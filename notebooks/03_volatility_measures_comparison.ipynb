{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Volatility Measures Comparison\n",
        "\n",
        "This notebook compares different ways to measure Bitcoin volatility and their sensitivity to market events.\n",
        "\n",
        "## Volatility Measures Tested:\n",
        "1. **Absolute Returns (Abs_Return)** - Simple daily price change magnitude\n",
        "2. **30-day Rolling Volatility** - Standard deviation of returns over 30 days\n",
        "3. **GARCH Volatility** - Model-based conditional volatility (if implemented)\n",
        "\n",
        "## Objectives:\n",
        "- Compare sensitivity of different volatility measures to events\n",
        "- Identify which measure best captures event impacts\n",
        "- Analyze the relationship between measures\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "ename": "ValueError",
          "evalue": "Missing column provided to 'parse_dates': 'Date'",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 12\u001b[39m\n\u001b[32m     10\u001b[39m \u001b[38;5;66;03m# Load data\u001b[39;00m\n\u001b[32m     11\u001b[39m project_root = Path(\u001b[33m'\u001b[39m\u001b[33m..\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m12\u001b[39m btc_data = \u001b[43mpd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mproject_root\u001b[49m\u001b[43m \u001b[49m\u001b[43m/\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mdata\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m/\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mraw\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m/\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mbitcoin_prices.csv\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[32m     13\u001b[39m \u001b[43m                       \u001b[49m\u001b[43mparse_dates\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mDate\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex_col\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mDate\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     14\u001b[39m events_data = pd.read_csv(project_root / \u001b[33m'\u001b[39m\u001b[33mdata\u001b[39m\u001b[33m'\u001b[39m / \u001b[33m'\u001b[39m\u001b[33mprocessed\u001b[39m\u001b[33m'\u001b[39m / \u001b[33m'\u001b[39m\u001b[33mmarket_events.csv\u001b[39m\u001b[33m'\u001b[39m, \n\u001b[32m     15\u001b[39m                           parse_dates=[\u001b[33m'\u001b[39m\u001b[33mdate\u001b[39m\u001b[33m'\u001b[39m])\n\u001b[32m     17\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mData loaded successfully!\u001b[39m\u001b[33m\"\u001b[39m)\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Python/Bitcoin/.conda/lib/python3.11/site-packages/pandas/io/parsers/readers.py:1026\u001b[39m, in \u001b[36mread_csv\u001b[39m\u001b[34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[39m\n\u001b[32m   1013\u001b[39m kwds_defaults = _refine_defaults_read(\n\u001b[32m   1014\u001b[39m     dialect,\n\u001b[32m   1015\u001b[39m     delimiter,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1022\u001b[39m     dtype_backend=dtype_backend,\n\u001b[32m   1023\u001b[39m )\n\u001b[32m   1024\u001b[39m kwds.update(kwds_defaults)\n\u001b[32m-> \u001b[39m\u001b[32m1026\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Python/Bitcoin/.conda/lib/python3.11/site-packages/pandas/io/parsers/readers.py:620\u001b[39m, in \u001b[36m_read\u001b[39m\u001b[34m(filepath_or_buffer, kwds)\u001b[39m\n\u001b[32m    617\u001b[39m _validate_names(kwds.get(\u001b[33m\"\u001b[39m\u001b[33mnames\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[32m    619\u001b[39m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m620\u001b[39m parser = \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    622\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[32m    623\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Python/Bitcoin/.conda/lib/python3.11/site-packages/pandas/io/parsers/readers.py:1620\u001b[39m, in \u001b[36mTextFileReader.__init__\u001b[39m\u001b[34m(self, f, engine, **kwds)\u001b[39m\n\u001b[32m   1617\u001b[39m     \u001b[38;5;28mself\u001b[39m.options[\u001b[33m\"\u001b[39m\u001b[33mhas_index_names\u001b[39m\u001b[33m\"\u001b[39m] = kwds[\u001b[33m\"\u001b[39m\u001b[33mhas_index_names\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m   1619\u001b[39m \u001b[38;5;28mself\u001b[39m.handles: IOHandles | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1620\u001b[39m \u001b[38;5;28mself\u001b[39m._engine = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Python/Bitcoin/.conda/lib/python3.11/site-packages/pandas/io/parsers/readers.py:1898\u001b[39m, in \u001b[36mTextFileReader._make_engine\u001b[39m\u001b[34m(self, f, engine)\u001b[39m\n\u001b[32m   1895\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg)\n\u001b[32m   1897\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1898\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmapping\u001b[49m\u001b[43m[\u001b[49m\u001b[43mengine\u001b[49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1899\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[32m   1900\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.handles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Python/Bitcoin/.conda/lib/python3.11/site-packages/pandas/io/parsers/c_parser_wrapper.py:161\u001b[39m, in \u001b[36mCParserWrapper.__init__\u001b[39m\u001b[34m(self, src, **kwds)\u001b[39m\n\u001b[32m    155\u001b[39m         \u001b[38;5;28mself\u001b[39m._validate_usecols_names(\n\u001b[32m    156\u001b[39m             usecols,\n\u001b[32m    157\u001b[39m             \u001b[38;5;28mself\u001b[39m.names,  \u001b[38;5;66;03m# type: ignore[has-type]\u001b[39;00m\n\u001b[32m    158\u001b[39m         )\n\u001b[32m    160\u001b[39m \u001b[38;5;66;03m# error: Cannot determine type of 'names'\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m161\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_validate_parse_dates_presence\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mnames\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore[has-type]\u001b[39;00m\n\u001b[32m    162\u001b[39m \u001b[38;5;28mself\u001b[39m._set_noconvert_columns()\n\u001b[32m    164\u001b[39m \u001b[38;5;66;03m# error: Cannot determine type of 'names'\u001b[39;00m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Python/Bitcoin/.conda/lib/python3.11/site-packages/pandas/io/parsers/base_parser.py:243\u001b[39m, in \u001b[36mParserBase._validate_parse_dates_presence\u001b[39m\u001b[34m(self, columns)\u001b[39m\n\u001b[32m    233\u001b[39m missing_cols = \u001b[33m\"\u001b[39m\u001b[33m, \u001b[39m\u001b[33m\"\u001b[39m.join(\n\u001b[32m    234\u001b[39m     \u001b[38;5;28msorted\u001b[39m(\n\u001b[32m    235\u001b[39m         {\n\u001b[32m   (...)\u001b[39m\u001b[32m    240\u001b[39m     )\n\u001b[32m    241\u001b[39m )\n\u001b[32m    242\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m missing_cols:\n\u001b[32m--> \u001b[39m\u001b[32m243\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    244\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mMissing column provided to \u001b[39m\u001b[33m'\u001b[39m\u001b[33mparse_dates\u001b[39m\u001b[33m'\u001b[39m\u001b[33m: \u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmissing_cols\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    245\u001b[39m     )\n\u001b[32m    246\u001b[39m \u001b[38;5;66;03m# Convert positions to actual column names\u001b[39;00m\n\u001b[32m    247\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m [\n\u001b[32m    248\u001b[39m     col \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;28misinstance\u001b[39m(col, \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m col \u001b[38;5;129;01min\u001b[39;00m columns) \u001b[38;5;28;01melse\u001b[39;00m columns[col]\n\u001b[32m    249\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m col \u001b[38;5;129;01min\u001b[39;00m cols_needed\n\u001b[32m    250\u001b[39m ]\n",
            "\u001b[31mValueError\u001b[39m: Missing column provided to 'parse_dates': 'Date'"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from pathlib import Path\n",
        "from scipy import stats\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Load data\n",
        "project_root = Path('..')\n",
        "btc_data = pd.read_csv(project_root / 'data' / 'raw' / 'bitcoin_prices.csv', \n",
        "                       parse_dates=['Date'], index_col='Date')\n",
        "events_data = pd.read_csv(project_root / 'data' / 'processed' / 'market_events.csv', \n",
        "                          parse_dates=['date'])\n",
        "\n",
        "print(\"Data loaded successfully!\")\n",
        "print(f\"Bitcoin data: {btc_data.shape}\")\n",
        "print(f\"Events data: {events_data.shape}\")\n",
        "\n",
        "# Check available volatility measures\n",
        "print(f\"\\nAvailable volatility measures in data:\")\n",
        "vol_measures = ['Abs_Return', 'Volatility_30d', 'Daily_Return']\n",
        "for measure in vol_measures:\n",
        "    if measure in btc_data.columns:\n",
        "        print(f\"  ✓ {measure}\")\n",
        "    else:\n",
        "        print(f\"  ✗ {measure}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create additional volatility measures for comparison\n",
        "print(\"Creating additional volatility measures...\")\n",
        "\n",
        "# 1. 7-day rolling volatility\n",
        "btc_data['Volatility_7d'] = btc_data['Daily_Return'].rolling(window=7).std()\n",
        "\n",
        "# 2. 14-day rolling volatility  \n",
        "btc_data['Volatility_14d'] = btc_data['Daily_Return'].rolling(window=14).std()\n",
        "\n",
        "# 3. Realized volatility (using absolute returns over different windows)\n",
        "btc_data['Realized_Vol_7d'] = btc_data['Abs_Return'].rolling(window=7).mean()\n",
        "btc_data['Realized_Vol_14d'] = btc_data['Abs_Return'].rolling(window=14).mean()\n",
        "\n",
        "# 4. High-Low volatility proxy\n",
        "btc_data['HL_Volatility'] = (btc_data['High'] - btc_data['Low']) / btc_data['Close']\n",
        "\n",
        "print(\"Additional volatility measures created:\")\n",
        "new_measures = ['Volatility_7d', 'Volatility_14d', 'Realized_Vol_7d', 'Realized_Vol_14d', 'HL_Volatility']\n",
        "for measure in new_measures:\n",
        "    print(f\"  ✓ {measure}\")\n",
        "\n",
        "# Show correlation matrix of all volatility measures\n",
        "vol_columns = ['Abs_Return', 'Volatility_30d', 'Volatility_7d', 'Volatility_14d', \n",
        "               'Realized_Vol_7d', 'Realized_Vol_14d', 'HL_Volatility']\n",
        "vol_data = btc_data[vol_columns].dropna()\n",
        "\n",
        "print(f\"\\nCorrelation matrix of volatility measures:\")\n",
        "correlation_matrix = vol_data.corr()\n",
        "print(correlation_matrix.round(3))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Visualize volatility measures comparison\n",
        "fig, axes = plt.subplots(3, 2, figsize=(15, 12))\n",
        "\n",
        "# Plot all volatility measures over time\n",
        "vol_measures_to_plot = ['Abs_Return', 'Volatility_7d', 'Volatility_14d', 'Volatility_30d', 'HL_Volatility']\n",
        "colors = ['blue', 'green', 'orange', 'red', 'purple']\n",
        "\n",
        "for i, (measure, color) in enumerate(zip(vol_measures_to_plot, colors)):\n",
        "    row = i // 2\n",
        "    col = i % 2\n",
        "    if row < 3 and col < 2:\n",
        "        axes[row, col].plot(btc_data.index, btc_data[measure], color=color, alpha=0.7, linewidth=1)\n",
        "        axes[row, col].set_title(f'{measure}', fontweight='bold')\n",
        "        axes[row, col].set_ylabel('Volatility')\n",
        "        axes[row, col].grid(True, alpha=0.3)\n",
        "\n",
        "# Remove empty subplot\n",
        "if len(vol_measures_to_plot) < 6:\n",
        "    axes[2, 1].remove()\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Correlation heatmap\n",
        "plt.figure(figsize=(10, 8))\n",
        "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', center=0, \n",
        "            square=True, fmt='.3f', cbar_kws={'label': 'Correlation'})\n",
        "plt.title('Volatility Measures Correlation Matrix', fontsize=14, fontweight='bold')\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Test event sensitivity for different volatility measures\n",
        "from datetime import timedelta\n",
        "\n",
        "def test_volatility_sensitivity(btc_data, events_data, vol_measure, window_days=10):\n",
        "    \"\"\"Test how sensitive a volatility measure is to events\"\"\"\n",
        "    results = []\n",
        "    \n",
        "    for idx, event in events_data.iterrows():\n",
        "        event_date = event['date']\n",
        "        \n",
        "        # Define before and after periods\n",
        "        before_start = event_date - timedelta(days=window_days)\n",
        "        before_end = event_date - timedelta(days=1)\n",
        "        after_start = event_date + timedelta(days=1)\n",
        "        after_end = event_date + timedelta(days=window_days)\n",
        "        \n",
        "        # Get data\n",
        "        before_data = btc_data[(btc_data.index >= before_start) & \n",
        "                              (btc_data.index <= before_end)][vol_measure].dropna()\n",
        "        after_data = btc_data[(btc_data.index >= after_start) & \n",
        "                             (btc_data.index <= after_end)][vol_measure].dropna()\n",
        "        \n",
        "        # Calculate change and significance\n",
        "        if len(before_data) > 3 and len(after_data) > 3:\n",
        "            before_mean = before_data.mean()\n",
        "            after_mean = after_data.mean()\n",
        "            change = after_mean - before_mean\n",
        "            change_pct = (change / before_mean) * 100 if before_mean != 0 else 0\n",
        "            \n",
        "            # T-test\n",
        "            t_stat, p_value = stats.ttest_ind(before_data, after_data)\n",
        "            significant = p_value < 0.05\n",
        "        else:\n",
        "            before_mean = after_mean = change = change_pct = t_stat = p_value = np.nan\n",
        "            significant = False\n",
        "        \n",
        "        results.append({\n",
        "            'event_id': event['event_id'],\n",
        "            'event': event['event'],\n",
        "            'severity': event['severity'],\n",
        "            'before_mean': before_mean,\n",
        "            'after_mean': after_mean,\n",
        "            'change': change,\n",
        "            'change_pct': change_pct,\n",
        "            't_statistic': t_stat,\n",
        "            'p_value': p_value,\n",
        "            'significant': significant\n",
        "        })\n",
        "    \n",
        "    return pd.DataFrame(results)\n",
        "\n",
        "# Test all volatility measures\n",
        "print(\"Testing event sensitivity for different volatility measures...\")\n",
        "vol_measures_to_test = ['Abs_Return', 'Volatility_7d', 'Volatility_14d', 'Volatility_30d', 'HL_Volatility']\n",
        "sensitivity_results = {}\n",
        "\n",
        "for measure in vol_measures_to_test:\n",
        "    print(f\"\\nTesting {measure}...\")\n",
        "    results = test_volatility_sensitivity(btc_data, events_data, measure)\n",
        "    sensitivity_results[measure] = results\n",
        "    \n",
        "    significant_count = results['significant'].sum()\n",
        "    mean_change = results['change'].mean()\n",
        "    print(f\"  Significant events: {significant_count}/{len(results)} ({significant_count/len(results)*100:.1f}%)\")\n",
        "    print(f\"  Mean change: {mean_change:.4f}\")\n",
        "\n",
        "# Summary comparison\n",
        "print(f\"\\n=== VOLATILITY MEASURES SENSITIVITY SUMMARY ===\")\n",
        "summary_data = []\n",
        "for measure, results in sensitivity_results.items():\n",
        "    summary_data.append({\n",
        "        'Measure': measure,\n",
        "        'Significant_Events': results['significant'].sum(),\n",
        "        'Significance_Rate': results['significant'].sum() / len(results) * 100,\n",
        "        'Mean_Change': results['change'].mean(),\n",
        "        'Mean_Change_Pct': results['change_pct'].mean()\n",
        "    })\n",
        "\n",
        "summary_df = pd.DataFrame(summary_data)\n",
        "print(summary_df.round(3))\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
